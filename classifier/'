from sklearn.pipeline import Pipeline
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import Normalizer
from sklearn import metrics
from sklearn.cluster import KMeans, MiniBatchKMeans
import pandas as pd
import warnings
import nltk
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction import DictVectorizer
from sklearn import linear_model
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import LinearSVC
from sklearn.svm import l1_min_c
from sklearn.svm import SVC
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.multiclass import OneVsRestClassifier
from sklearn.multiclass import OneVsOneClassifier
from sklearn.metrics import accuracy_score
from sklearn import preprocessing
import numpy as np

warnings.filterwarnings("ignore", category=DeprecationWarning, module="pandas", lineno=570) 
class Machine:
    def __init__(self):
        self.classifier, self.bin_labels = make_svm()

def get_data(data_type='trial'):
	x_train = []
	y_train = []
	with open('../datasets/'+data_type+'/affectivetext_'+data_type+'.emotions.simple', 'r') as f:
		for line in f:
			line_split = line.split(' ')
			y_train.append(line_split[1].rstrip())
	with open('../datasets/'+data_type+'/affectivetext_'+data_type, 'r') as x:
		for line in x:
			line_split = line.split(' ')
			x_train.append(' '.join(line_split[1:]).rstrip())
	return x_train, y_train 

                 
def make_svm(): #Trains the SVM
    X_train, y_train_text = get_data('trial')
 
 
    lb = preprocessing.LabelBinarizer()
    Y = lb.fit_transform(y_train_text) 
    classifier = Pipeline([
        ('vectorizer', CountVectorizer()),
        ('tfidf', TfidfTransformer()),
        ('clf', OneVsRestClassifier(LinearSVC()))])
 
    classifier.fit(X_train, Y) 
    return classifier, lb
 
if __name__ == "__main__": 
    man = Machine() 
    classifier, labelb = make_svm()
stemmer = PorterStemmer()


def stem_tokens(tokens, stemmer):
    stemmed = []
    for item in tokens:
	stemmed_item = stemmer.stem(item)
	if len(stemmed_item) > 1:
        	stemmed.append(stemmed_item)
    return stemmed

def tokenize(text):
    tokens = nltk.word_tokenize(text)
    stems = stem_tokens(tokens, stemmer)
    return stems


x, y = get_data()
x_t, y_t = get_data('test')

X_train = np.array(x)
y_train = y 


tsv = TruncatedSVD(algorithm='randomized', n_iterations=5)
tfv = TfidfVectorizer(min_df=3, analyzer='word', token_pattern=r'\w{1,}', ngram_range=(1,2), use_idf=1, smooth_idf=1, sublinear_tf=1)
tfv.fit(x)
#text = tfv.transform(x)
print text
tsv.fit(text)


vectorizer = CountVectorizer(min_df=1, stop_words='english')
dtm = vectorizer.fit_transform(X_train)
print vectorizer.get_feature_names()
lsa = TruncatedSVD(2, algorithm = 'arpack')
dtm_lsa = lsa.fit_transform(dtm)
dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)


classifier = Pipeline([
    #('vectorizer', CountVectorizer(analyzer='word',strip_accents='unicode', stop_words='english', binary=True )),
    #('tfidf', TfidfVectorizer(analyzer='word', tokenizer=tokenize, stop_words='english')),
    #('tfidf', TfidfTransformer()),
    ('clf', MultinomialNB())])


classifier = classifier.fit(dtm_lsa, y_train)
predicted = classifier.predict(x_t)


print accuracy_score(predicted, y_t)
